{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqszj_KQlBL4",
        "outputId": "0088db01-219a-40b6-c96d-e557f2f18eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->wikipedia-api) (2025.1.31)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=be25afccd44e2b159dc3795a9d88fa39ae67c7b313dcab8111328a905ca0d9bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia-api\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "R9zPM_SAeh4B"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk import NaiveBayesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgqiOUTbt7by",
        "outputId": "c013813e-7444-4562-883f-6052bb66fae3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Define lists of terms\n",
        "location_terms = [\"region\", \"area\", \"terrain\", \"nation\", \"town\"]\n",
        "non_location_terms = [\"innovation\", \"knowledge\", \"machine learning\", \"computing\"]\n",
        "\n",
        "def fetch_wikipedia_content(topic, relevant_terms):\n",
        "    \"\"\"\n",
        "    Fetch Wikipedia content and find relevant terms within it.\n",
        "    \"\"\"\n",
        "    wiki_api = wikipediaapi.Wikipedia('en',\n",
        "                                    extract_format=wikipediaapi.ExtractFormat.WIKI,\n",
        "                                    headers={'User-Agent': 'Farid_Tavakkolinia'})\n",
        "\n",
        "    wiki_page = wiki_api.page(topic)\n",
        "\n",
        "    if wiki_page.exists():\n",
        "        content = wiki_page.text\n",
        "        found_terms = [term for term in relevant_terms if term.lower() in content.lower()]\n",
        "        return content, found_terms\n",
        "    else:\n",
        "        print(f\"Wikipedia page for '{topic}' does not exist.\")\n",
        "        return None, None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOJuM7nEeh61",
        "outputId": "efc33e5f-d3bb-478a-9cc7-b90912c8d466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content for 'Machine learning':\n",
            "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
            "ML finds application in many fields, \n",
            "Found Terms: ['knowledge', 'machine learning', 'computing']\n"
          ]
        }
      ],
      "source": [
        "topic = \"Machine learning\"\n",
        "content, found_terms = fetch_wikipedia_content(topic, non_location_terms)\n",
        "\n",
        "if content:\n",
        "    print(f\"Content for '{topic}':\")\n",
        "    print(content[:500])  # Display the first 500 characters of the content\n",
        "    print(\"Found Terms:\", found_terms)\n",
        "\n",
        "def preprocess_text(text, terms, stopwords_set=None, stemmer=None, lemmatizer=None):\n",
        "    \"\"\"\n",
        "    Preprocess text with optional stopwords, stemming, and lemmatization.\n",
        "    \"\"\"\n",
        "    # Use provided stopwords set or default to NLTK stop words\n",
        "    stopwords_set = stopwords_set or set(stopwords.words('english'))\n",
        "\n",
        "    # Use provided stemmer/lemmatizer or default ones\n",
        "    stemmer = stemmer or PorterStemmer()\n",
        "    lemmatizer = lemmatizer or WordNetLemmatizer()\n",
        "\n",
        "    # Tokenize and process\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    tokens = [token for token in tokens if token.isalpha()]\n",
        "\n",
        "    # Remove very short words \n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Remove stopwords\n",
        "    filtered_tokens = [token for token in tokens if token not in stopwords_set]\n",
        "\n",
        "    # Apply stemming\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "\n",
        "    # Remove terms from the feature set to avoid direct matching\n",
        "    processed_text = ' '.join(stemmed_tokens)\n",
        "\n",
        "    return processed_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fVZhIn-eh9x",
        "outputId": "1406de54-9021-4ea7-bf88-4764b5527df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bag of Words without preprocessing:\n",
            "{'machine': True, 'learning': True, '(': True, 'ml': True, ')': True, 'is': True, 'a': True, 'field': True, 'of': True, 'study': True, 'in': True, 'artificial': True, 'intelligence': True, 'concerned': True, 'with': True, 'the': True, 'development': True, 'and': True, 'statistical': True, 'algorithms': True, 'that': True, 'can': True, 'learn': True, 'from': True, 'data': True, 'generalize': True, 'to': True, 'unseen': True, ',': True, 'thus': True, 'perform': True, 'tasks': True, 'without': True, 'explicit': True, 'instructions': True, '.': True, 'within': True, 'subdiscipline': True, 'advances': True, 'deep': True, 'have': True, 'allowed': True, 'neural': True, 'networks': True, 'class': True, 'surpass': True, 'many': True, 'previous': True, 'approaches': True, 'performance': True, 'finds': True, 'application': True, 'fields': True, 'including': True, 'natural': True, 'language': True, 'processing': True, 'computer': True, 'vision': True, 'speech': True, 'recognition': True, 'email': True, 'filtering': True, 'agriculture': True, 'medicine': True, 'business': True, 'problems': True, 'known': True, 'as': True, 'predictive': True, 'analytics': True, 'statistics': True, 'mathematical': True, 'optimization': True, 'programming': True, 'methods': True, 'comprise': True, 'foundations': True, 'mining': True, 'related': True, 'focusing': True, 'on': True, 'exploratory': True, 'analysis': True, 'eda': True, 'via': True, 'unsupervised': True, 'theoretical': True, 'viewpoint': True, 'probably': True, 'approximately': True, 'correct': True, 'provides': True, 'framework': True, 'for': True, 'describing': True, 'history': True, 'term': True, 'was': True, 'coined': True, '1959': True, 'by': True, 'arthur': True, 'samuel': True, 'an': True, 'ibm': True, 'employee': True, 'pioneer': True, 'gaming': True, 'synonym': True, 'self-teaching': True, 'computers': True, 'also': True, 'used': True, 'this': True, 'time': True, 'period': True, 'although': True, 'earliest': True, 'model': True, 'introduced': True, '1950s': True, 'when': True, 'invented': True, 'program': True, 'calculated': True, 'winning': True, 'chance': True, 'checkers': True, 'each': True, 'side': True, 'roots': True, 'back': True, 'decades': True, 'human': True, 'desire': True, 'effort': True, 'cognitive': True, 'processes': True, '1949': True, 'canadian': True, 'psychologist': True, 'donald': True, 'hebb': True, 'published': True, 'book': True, 'organization': True, 'behavior': True, 'which': True, 'he': True, 'structure': True, 'formed': True, 'certain': True, 'interactions': True, 'among': True, 'nerve': True, 'cells': True, \"'s\": True, 'neurons': True, 'interacting': True, 'one': True, 'another': True, 'set': True, 'groundwork': True, 'how': True, 'ais': True, 'work': True, 'under': True, 'nodes': True, 'or': True, 'communicate': True, 'other': True, 'researchers': True, 'who': True, 'studied': True, 'systems': True, 'contributed': True, 'modern': True, 'technologies': True, 'well': True, 'logician': True, 'walter': True, 'pitts': True, 'warren': True, 'mcculloch': True, 'proposed': True, 'early': True, 'models': True, 'come': True, 'up': True, 'mirror': True, 'thought': True, '1960s': True, 'experimental': True, '``': True, \"''\": True, 'punched': True, 'tape': True, 'memory': True, 'called': True, 'cybertron': True, 'had': True, 'been': True, 'developed': True, 'raytheon': True, 'company': True, 'analyse': True, 'sonar': True, 'signals': True, 'electrocardiograms': True, 'patterns': True, 'using': True, 'rudimentary': True, 'reinforcement': True, 'it': True, 'repetitively': True, 'trained': True, 'operator/teacher': True, 'recognize': True, 'equipped': True, 'goof': True, 'button': True, 'cause': True, 'reevaluate': True, 'incorrect': True, 'decisions': True, 'representative': True, 'research': True, 'into': True, 'during': True, 'nilsson': True, 'machines': True, 'dealing': True, 'mostly': True, 'pattern': True, 'classification': True, 'interest': True, 'continued': True, '1970s': True, 'described': True, 'duda': True, 'hart': True, '1973.': True, '1981': True, 'report': True, 'given': True, 'teaching': True, 'strategies': True, 'so': True, 'network': True, 'learns': True, '40': True, 'characters': True, '26': True, 'letters': True, '10': True, 'digits': True, '4': True, 'special': True, 'symbols': True, 'terminal': True, 'tom': True, 'm.': True, 'mitchell': True, 'provided': True, 'widely': True, 'quoted': True, 'more': True, 'formal': True, 'definition': True, ':': True, 'said': True, 'experience': True, 'e': True, 'respect': True, 'some': True, 't': True, 'measure': True, 'p': True, 'if': True, 'its': True, 'at': True, 'measured': True, 'improves': True, 'e.': True, 'offers': True, 'fundamentally': True, 'operational': True, 'rather': True, 'than': True, 'defining': True, 'terms': True, 'follows': True, 'alan': True, 'turing': True, 'proposal': True, 'his': True, 'paper': True, 'computing': True, 'machinery': True, 'question': True, 'think': True, '?': True, 'replaced': True, 'do': True, 'what': True, 'we': True, 'thinking': True, 'entities': True, 'modern-day': True, 'has': True, 'two': True, 'objectives': True, 'classify': True, 'based': True, ';': True, 'purpose': True, 'make': True, 'predictions': True, 'future': True, 'outcomes': True, 'these': True, 'hypothetical': True, 'algorithm': True, 'specific': True, 'classifying': True, 'may': True, 'use': True, 'moles': True, 'coupled': True, 'supervised': True, 'order': True, 'train': True, 'cancerous': True, 'stock': True, 'trading': True, 'inform': True, 'trader': True, 'potential': True, 'relationships': True, 'scientific': True, 'endeavor': True, 'grew': True, 'out': True, 'quest': True, 'ai': True, 'days': True, 'academic': True, 'discipline': True, 'were': True, 'interested': True, 'having': True, 'they': True, 'attempted': True, 'approach': True, 'problem': True, 'various': True, 'symbolic': True, 'then': True, 'termed': True, 'perceptrons': True, 'later': True, 'found': True, 'be': True, 'reinventions': True, 'generalized': True, 'linear': True, 'probabilistic': True, 'reasoning': True, 'employed': True, 'especially': True, 'automated': True, 'medical': True, 'diagnosis': True, '488': True, 'however': True, 'increasing': True, 'emphasis': True, 'logical': True, 'knowledge-based': True, 'caused': True, 'rift': True, 'between': True, 'plagued': True, 'practical': True, 'acquisition': True, 'representation': True, '1980': True, 'expert': True, 'dominate': True, 'favor': True, 'symbolic/knowledge-based': True, 'did': True, 'continue': True, 'leading': True, 'inductive': True, 'logic': True, 'ilp': True, 'but': True, 'line': True, 'now': True, 'outside': True, 'proper': True, 'information': True, 'retrieval': True, '708–710': True, '755': True, 'abandoned': True, 'science': True, 'around': True, 'same': True, 'too': True, 'ai/cs': True, 'connectionism': True, 'disciplines': True, 'john': True, 'hopfield': True, 'david': True, 'rumelhart': True, 'geoffrey': True, 'hinton': True, 'their': True, 'main': True, 'success': True, 'came': True, 'mid-1980s': True, 'reinvention': True, 'backpropagation': True, '25': True, 'reorganized': True, 'recognized': True, 'own': True, 'started': True, 'flourish': True, '1990s': True, 'changed': True, 'goal': True, 'achieving': True, 'tackling': True, 'solvable': True, 'nature': True, 'shifted': True, 'focus': True, 'away': True, 'inherited': True, 'toward': True, 'borrowed': True, 'fuzzy': True, 'probability': True, 'theory': True, 'compression': True, 'often': True, 'employ': True, 'overlap': True, 'significantly': True, 'while': True, 'focuses': True, 'prediction': True, 'properties': True, 'learned': True, 'training': True, 'discovery': True, 'previously': True, 'unknown': True, 'step': True, 'knowledge': True, 'databases': True, 'uses': True, 'different': True, 'goals': True, 'hand': True, 'employs': True, 'preprocessing': True, 'improve': True, 'learner': True, 'accuracy': True, 'much': True, 'confusion': True, 'communities': True, 'separate': True, 'conferences': True, 'journals': True, 'ecml': True, 'pkdd': True, 'being': True, 'major': True, 'exception': True, 'comes': True, 'basic': True, 'assumptions': True, 'usually': True, 'evaluated': True, 'ability': True, 'reproduce': True, 'kdd': True, 'key': True, 'task': True, 'uninformed': True, 'method': True, 'will': True, 'easily': True, 'outperformed': True, 'typical': True, 'not': True, 'due': True, 'unavailability': True, 'intimate': True, 'ties': True, 'are': True, 'formulated': True, 'minimization': True, 'loss': True, 'function': True, 'examples': True, 'functions': True, 'express': True, 'discrepancy': True, 'actual': True, 'instances': True, 'example': True, 'wants': True, 'assign': True, 'label': True, 'correctly': True, 'predict': True, 'preassigned': True, 'labels': True, 'generalization': True, 'characterizing': True, 'active': True, 'topic': True, 'current': True, 'closely': True, 'distinct': True, 'principal': True, 'draws': True, 'population': True, 'inferences': True, 'sample': True, 'generalizable': True, 'according': True, 'michael': True, 'i.': True, 'jordan': True, 'ideas': True, 'methodological': True, 'principles': True, 'tools': True, 'long': True, 'pre-history': True, 'suggested': True, 'placeholder': True, 'call': True, 'overall': True, 'conventional': True, 'analyses': True, 'require': True, 'priori': True, 'selection': True, 'most': True, 'suitable': True, 'addition': True, 'only': True, 'significant': True, 'theoretically': True, 'relevant': True, 'variables': True, 'included': True, 'contrast': True, 'built': True, 'pre-structured': True, 'shape': True, 'detecting': True, 'underlying': True, 'input': True, 'accurate': True, 'ultimate': True, 'leo': True, 'breiman': True, 'distinguished': True, 'modeling': True, 'paradigms': True, 'algorithmic': True, 'wherein': True, 'means': True, 'less': True, 'like': True, 'random': True, 'forest': True, 'statisticians': True, 'adopted': True, 'combined': True, 'physics': True, 'analytical': True, 'computational': True, 'techniques': True, 'derived': True, 'deep-rooted': True, 'disordered': True, 'extended': True, 'large-scale': True, 'e.g.': True, 'weight': True, 'space': True, 'finding': True, 'applications': True, 'area': True, 'diagnostics': True, 'core': True, 'objective': True, 'context': True, 'accurately': True, 'new': True, 'examples/tasks': True, 'after': True, 'experienced': True, 'generally': True, 'distribution': True, 'considered': True, 'occurrences': True, 'build': True, 'general': True, 'about': True, 'enables': True, 'produce': True, 'sufficiently': True, 'cases': True, 'branch': True, 'because': True, 'sets': True, 'finite': True, 'uncertain': True, 'does': True, 'yield': True, 'guarantees': True, 'instead': True, 'bounds': True, 'quite': True, 'common': True, 'bias–variance': True, 'decomposition': True, 'way': True, 'quantify': True, 'error': True, 'best': True, 'complexity': True, 'hypothesis': True, 'should': True, 'match': True, 'complex': True, 'fitted': True, 'increased': True, 'response': True, 'decreases': True, 'subject': True, 'overfitting': True, 'poorer': True, 'theorists': True, 'feasibility': True, 'computation': True, 'feasible': True, 'done': True, 'polynomial': True, 'there': True, 'kinds': True, 'results': True, 'positive': True, 'show': True, 'negative': True, 'classes': True, 'traditionally': True, 'divided': True, 'three': True, 'broad': True, 'categories': True, 'correspond': True, 'depending': True, 'signal': True, 'feedback': True, 'available': True, 'system': True, 'presented': True, 'inputs': True, 'desired': True, 'outputs': True, 'teacher': True, 'rule': True, 'maps': True, 'no': True, 'leaving': True, 'find': True, 'itself': True, 'discovering': True, 'hidden': True, 'towards': True, 'end': True, 'feature': True, 'interacts': True, 'dynamic': True, 'environment': True, 'must': True, 'such': True, 'driving': True, 'vehicle': True, 'playing': True, 'game': True, 'against': True, 'opponent': True, 'navigates': True, 'analogous': True, 'rewards': True, 'tries': True, 'maximize': True, 'advantages': True, 'limitations': True, 'single': True, 'works': True, 'all': True, 'contains': True, 'both': True, 'consists': True, 'output': True, 'supervisory': True, 'represented': True, 'array': True, 'vector': True, 'sometimes': True, 'matrix': True, 'through': True, 'iterative': True, 'associated': True, 'optimal': True, 'allows': True, 'determine': True, 'part': True, 'over': True, 'types': True, 'supervised-learning': True, 'include': True, 'regression': True, 'restricted': True, 'limited': True, 'values': True, 'any': True, 'numerical': True, 'value': True, 'range': True, 'filters': True, 'emails': True, 'would': True, 'incoming': True, 'name': True, 'folder': True, 'file': True, 'predicting': True, 'height': True, 'person': True, 'temperature': True, 'similarity': True, 'measures': True, 'similar': True, 'objects': True, 'ranking': True, 'recommendation': True, 'visual': True, 'identity': True, 'tracking': True, 'face': True, 'verification': True, 'speaker': True, 'structures': True, 'labeled': True, 'classified': True, 'categorized': True, 'responding': True, 'identify': True, 'commonalities': True, 'react': True, 'presence': True, 'absence': True, 'piece': True, 'central': True, 'clustering': True, 'dimensionality': True, 'reduction': True, 'density': True, 'estimation': True, 'cluster': True, 'assignment': True, 'observations': True, 'subsets': True, 'clusters': True, 'predesignated': True, 'criteria': True, 'drawn': True, 'dissimilar': True, 'defined': True, 'metric': True, 'internal': True, 'compactness': True, 'members': True, 'separation': True, 'difference': True, 'estimated': True, 'graph': True, 'connectivity': True, 'type': True, 'self-supervised': True, 'involves': True, 'generating': True, 'semi-supervised': True, 'falls': True, 'completely': True, 'missing': True, 'yet': True, 'machine-learning': True, 'unlabeled': True, 'conjunction': True, 'small': True, 'amount': True, 'considerable': True, 'improvement': True, 'weakly': True, 'noisy': True, 'imprecise': True, 'cheaper': True, 'obtain': True, 'resulting': True, 'larger': True, 'effective': True, 'software': True, 'agents': True, 'ought': True, 'take': True, 'actions': True, 'notion': True, 'cumulative': True, 'reward': True, 'generality': True, 'control': True, 'operations': True, 'simulation-based': True, 'multi-agent': True, 'swarm': True, 'genetic': True, 'typically': True, 'markov': True, 'decision': True, 'process': True, 'mdp': True, 'reinforcements': True, 'assume': True, 'exact': True, 'infeasible': True, 'autonomous': True, 'vehicles': True, 'play': True, 'reducing': True, 'number': True, 'consideration': True, 'obtaining': True, 'words': True, 'dimension': True, 'features': True, 'either': True, 'elimination': True, 'extraction': True, 'popular': True, 'component': True, 'pca': True, 'changing': True, 'higher-dimensional': True, '3d': True, 'smaller': True, '2d': True, 'manifold': True, 'proposes': True, 'high-dimensional': True, 'lie': True, 'along': True, 'low-dimensional': True, 'manifolds': True, 'assumption': True, 'regularization': True, 'fit': True, 'neatly': True, 'three-fold': True, 'categorization': True, 'meta-learning': True, 'self-learning': True, 'paradigm': True, '1982': True, 'capable': True, 'named': True, 'crossbar': True, 'adaptive': True, 'caa': True, 'gives': True, 'solution': True, 'external': True, 'introducing': True, 'emotion': True, 'state': True, 'evaluation': True, 'agent': True, 'computes': True, 'fashion': True, 'emotions': True, 'feelings': True, 'consequence': True, 'situations': True, 'driven': True, 'interaction': True, 'cognition': True, 'updates': True, 'w': True, '=||w': True, 's': True, '||': True, 'iteration': True, 'executes': True, 'following': True, 'routine': True, 'situation': True, 'action': True, 'receive': True, \"'\": True, 'compute': True, 'v': True, 'update': True, '=': True, '+': True, 'a.': True, 'neither': True, 'nor': True, 'advice': True, 'backpropagated': True, 'secondary': True, 'exists': True, 'environments': True, 'behavioral': True, 'where': True, 'behaves': True, 'wherefrom': True, 'initially': True, 'once': True, 'receives': True, 'initial': True, 'encountered': True, 'receiving': True, 'genome': True, 'species': True, 'goal-seeking': True, 'desirable': True, 'undesirable': True, 'several': True, 'aim': True, 'better': True, 'representations': True, 'classic': True, 'attempt': True, 'preserve': True, 'transform': True, 'makes': True, 'useful': True, 'pre-processing': True, 'before': True, 'performing': True, 'technique': True, 'reconstruction': True, 'coming': True, 'data-generating': True, 'necessarily': True, 'faithful': True, 'configurations': True, 'implausible': True, 'replaces': True, 'manual': True, 'engineering': True, 'them': True, 'multilayer': True, 'dictionary': True, 'independent': True, 'autoencoders': True, 'factorization': True, 'forms': True, 'constraint': True, 'sparse': True, 'coding': True, 'meaning': True, 'zeros': True, 'multilinear': True, 'subspace': True, 'directly': True, 'tensor': True, 'multidimensional': True, 'reshaping': True, 'vectors': True, 'discover': True, 'multiple': True, 'levels': True, 'hierarchy': True, 'higher-level': True, 'abstract': True, 'lower-level': True, 'argued': True, 'intelligent': True, 'disentangles': True, 'factors': True, 'variation': True, 'explain': True, 'observed': True, 'motivated': True, 'fact': True, 'mathematically': True, 'computationally': True, 'convenient': True, 'real-world': True, 'images': True, 'video': True, 'sensory': True, 'yielded': True, 'attempts': True, 'algorithmically': True, 'define': True, 'alternative': True, 'examination': True, 'relying': True, 'combination': True, 'basis': True, 'assumed': True, 'strongly': True, 'np-hard': True, 'difficult': True, 'solve': True, 'heuristic': True, 'k-svd': True, 'applied': True, 'contexts': True, 'belongs': True, 'already': True, 'sparsely': True, 'corresponding': True, 'image': True, 'de-noising': True, 'idea': True, 'clean': True, 'patch': True, 'noise': True, 'anomaly': True, 'detection': True, 'outlier': True, 'identification': True, 'rare': True, 'items': True, 'events': True, 'raise': True, 'suspicions': True, 'differing': True, 'majority': True, 'anomalous': True, 'represent': True, 'issue': True, 'bank': True, 'fraud': True, 'structural': True, 'defect': True, 'errors': True, 'text': True, 'anomalies': True, 'referred': True, 'outliers': True, 'novelties': True, 'deviations': True, 'exceptions': True, 'particular': True, 'abuse': True, 'intrusion': True, 'interesting': True, 'unexpected': True, 'bursts': True, 'inactivity': True, 'adhere': True, 'object': True, 'fail': True, 'unless': True, 'aggregated': True, 'appropriately': True, 'able': True, 'detect': True, 'micro-clusters': True, 'exist': True, 'test': True, 'normal': True, 'looking': True, 'seem': True, 'least': True, 'remainder': True, 'abnormal': True, 'classifier': True, 'inherently': True, 'unbalanced': True, 'construct': True, 'representing': True, 'likelihood': True, 'instance': True, 'generated': True, 'robot': True, 'inspired': True, 'multitude': True, 'starting': True, 'finally': True, 'e.g': True, 'maml': True, 'association': True, 'rules': True, 'rule-based': True, 'large': True, 'intended': True, 'strong': True, 'discovered': True, 'interestingness': True, 'identifies': True, 'evolves': True, 'store': True, 'manipulate': True, 'apply': True, 'characteristic': True, 'utilization': True, 'relational': True, 'collectively': True, 'captured': True, 'commonly': True, 'singular': True, 'universally': True, 'immune': True, 'concept': True, 'rakesh': True, 'agrawal': True, 'tomasz': True, 'imieliński': True, 'arun': True, 'swami': True, 'regularities': True, 'products': True, 'transaction': True, 'recorded': True, 'point-of-sale': True, 'pos': True, 'supermarkets': True, '{': True, 'o': True, 'n': True, 'i': True, '}': True, '⇒': True, 'b': True, 'u': True, 'r': True, 'g': True, '\\\\displaystyle': True, '\\\\': True, '\\\\mathrm': True, 'onions': True, 'potatoes': True, '\\\\rightarrow': True, 'burger': True, 'sales': True, 'supermarket': True, 'indicate': True, 'customer': True, 'buys': True, 'together': True, 'likely': True, 'buy': True, 'hamburger': True, 'meat': True, 'marketing': True, 'activities': True, 'promotional': True, 'pricing': True, 'product': True, 'placements': True, 'market': True, 'basket': True, 'today': True, 'areas': True, 'web': True, 'usage': True, 'continuous': True, 'production': True, 'bioinformatics': True, 'sequence': True, 'consider': True, 'across': True, 'transactions': True, 'lcs': True, 'family': True, 'combine': True, 'seek': True, 'context-dependent': True, 'piecewise': True, 'manner': True, 'uniform': True, 'background': True, 'hypotheses': True, 'encoding': True, 'database': True, 'facts': True, 'derive': True, 'hypothesized': True, 'entails': True, 'considers': True, 'kind': True, 'functional': True, 'programs': True, 'particularly': True, 'gordon': True, 'plotkin': True, 'ehud': True, 'shapiro': True, 'laid': True, 'foundation': True, 'setting': True, 'first': True, 'implementation': True, 'inference': True, 'prolog': True, 'inductively': True, 'inferred': True, 'here': True, 'refers': True, 'philosophical': True, 'induction': True, 'suggesting': True, 'proving': True, 'property': True, 'well-ordered': True, 'dataset': True, 'classifications': True, 'iteratively': True, 'adjusts': True, 'parameters': True, 'minimize': True, 'extension': True, 'refer': True, 'specificity': True, 'fully': True, 'tuned': True, 'researched': True, 'picking': True, 'anns': True, 'connectionist': True, 'vaguely': True, 'biological': True, 'constitute': True, 'animal': True, 'brains': True, 'considering': True, 'programmed': True, 'task-specific': True, 'ann': True, 'collection': True, 'connected': True, 'units': True, 'loosely': True, 'brain': True, 'connection': True, 'synapses': True, 'transmit': True, 'neuron': True, 'additional': True, 'implementations': True, 'real': True, 'computed': True, 'non-linear': True, 'sum': True, 'connections': True, 'edges': True, 'proceeds': True, 'increases': True, 'strength': True, 'threshold': True, 'sent': True, 'aggregate': True, 'crosses': True, 'layers': True, 'transformations': True, 'travel': True, 'layer': True, 'last': True, 'possibly': True, 'traversing': True, 'times': True, 'original': True, 'attention': True, 'moved': True, 'biology': True, 'variety': True, 'translation': True, 'social': True, 'board': True, 'games': True, 'light': True, 'sound': True, 'hearing': True, 'successful': True, 'trees': True, 'tree': True, 'go': True, 'item': True, 'branches': True, 'conclusions': True, 'target': True, 'leaves': True, 'variable': True, 'discrete': True, 'conjunctions': True, 'lead': True, 'those': True, 'numbers': True, 'visually': True, 'explicitly': True, 'making': True, 'describes': True, 'decision-making': True, 'rfr': True, 'umbrella': True, 'tree-based': True, 'ensemble': True, 'builds': True, 'averages': True, 'avoid': True, 'bootstrapped': True, 'sampling': True, 'reduce': True, 'bias': True, 'achieve': True, 'generates': True, 'regressor': True, 'compatible': True, 'support-vector': True, 'svms': True, 'marked': True, 'belonging': True, 'svm': True, 'predicts': True, 'whether': True, 'category': True, 'non-probabilistic': True, 'binary': True, 'platt': True, 'scaling': True, 'efficiently': True, 'kernel': True, 'trick': True, 'implicitly': True, 'mapping': True, 'spaces': True, 'encompasses': True, 'estimate': True, 'relationship': True, 'form': True, 'criterion': True, 'ordinary': True, 'squares': True, 'latter': True, 'mitigate': True, 'ridge': True, 'go-to': True, 'trendline': True, 'fitting': True, 'microsoft': True, 'excel': True, 'logistic': True, 'even': True, 'introduces': True, 'non-linearity': True, 'taking': True, 'advantage': True, 'map': True, 'multivariate': True, 'extends': True, 'handle': True, 'dependent': True, 'simultaneously': True, 'estimates': True, 'scenarios': True, 'interdependent': True, 'share': True, 'economic': True, 'indicators': True, 'reconstructing': True, 'multi-dimensional': True, 'bayesian': True, 'belief': True, 'directed': True, 'acyclic': True, 'graphical': True, 'represents': True, 'conditional': True, 'independence': True, 'dag': True, 'could': True, 'diseases': True, 'symptoms': True, 'probabilities': True, 'efficient': True, 'sequences': True, 'protein': True, 'generalizations': True, 'uncertainty': True, 'influence': True, 'diagrams': True, 'gaussian': True, 'stochastic': True, 'every': True, 'relies': True, 'pre-defined': True, 'covariance': True, 'pairs': True, 'points': True, 'relate': True, 'locations': True, 'input–output': True, 'unobserved': True, 'point': True, 'covariances': True, 'surrogate': True, 'hyperparameter': True, 'ga': True, 'search': True, 'mimics': True, 'mutation': True, 'crossover': True, 'generate': True, 'genotypes': True, 'hope': True, 'good': True, 'solutions': True, '1980s': True, 'conversely': True, 'evolutionary': True, 'evidence': True, 'dempster–shafer': True, 'understood': True, 'frameworks': True, 'possibility': True, 'theories': True, 'dempster': True, 'just': True, 'pmf-based': True, 'caveats': True, 'beliefs': True, 'compared': True, 'incorporate': True, 'ignorance': True, 'quantification': True, 'implemented': True, 'domain': True, 'leverage': True, 'fusion': True, 'boundary': True, 'low': True, 'samples': True, 'ambiguous': True, 'issues': True, 'standard': True, 'tend': True, 'difficulty': True, 'resolving': True, 'propositions': True, 'higher': True, 'high': True, 'quantity': True, 'reliable': True, 'engineers': True, 'need': True, 'collect': True, 'varied': True, 'corpus': True, 'sensor': True, 'collected': True, 'individual': True, 'users': True, 'service': True, 'something': True, 'watch': True, 'biased': True, 'non-evaluated': True, 'result': True, 'skewed': True, 'undesired': True, 'detrimental': True, 'thereby': True, 'furthering': True, 'impacts': True, 'society': True, 'prepared': True, 'ethics': True, 'becoming': True, 'notably': True, 'integrated': True, 'teams': True, 'federated': True, 'adapted': True, 'distributed': True, 'decentralizes': True, 'allowing': True, 'privacy': True, 'maintained': True, 'needing': True, 'send': True, 'centralized': True, 'server': True, 'efficiency': True, 'decentralizing': True, 'devices': True, 'gboard': True, 'query': True, 'mobile': True, 'phones': True, 'searches': True, 'google': True, '2006': True, 'media-services': True, 'provider': True, 'netflix': True, 'held': True, 'prize': True, 'competition': True, 'user': True, 'preferences': True, 'existing': True, 'cinematch': True, 'movie': True, '%': True, 'joint': True, 'team': True, 'made': True, '&': True, 'labs-research': True, 'collaboration': True, 'big': True, 'chaos': True, 'pragmatic': True, 'win': True, 'grand': True, '2009': True, '$': True, '1': True, 'million': True, 'shortly': True, 'awarded': True, 'realized': True, 'viewers': True, 'ratings': True, 'viewing': True, 'everything': True, 'engine': True, 'accordingly': True, '2010': True, 'wall': True, 'street': True, 'journal': True, 'wrote': True, 'firm': True, 'rebellion': True, 'financial': True, 'crisis': True, '2012': True, 'co-founder': True, 'sun': True, 'microsystems': True, 'vinod': True, 'khosla': True, 'predicted': True, '80': True, 'doctors': True, 'jobs': True, 'lost': True, 'next': True, 'diagnostic': True, '2014': True, 'reported': True, 'art': True, 'fine': True, 'paintings': True, 'revealed': True, 'unrecognized': True, 'influences': True, 'artists': True, '2019': True, 'springer': True, 'created': True, '2020': True, 'technology': True, 'help': True, 'diagnoses': True, 'aid': True, 'developing': True, 'cure': True, 'covid-19': True, 'recently': True, 'pro-environmental': True, 'travelers': True, 'optimize': True, 'smartphone': True, 'thermal': True, 'phone': True, 'mlas': True, 'utilize': True, 'wide': True, 'characteristics': True, 'returns': True, 'employing': True, 'combining': True, 'forecasts': True, 'far': True, 'obtained': True, 'ols': True, 'recent': True, 'advancements': True, 'quantum': True, 'chemistry': True, 'novel': True, 'enable': True, 'solvent': True, 'effects': True, 'chemical': True, 'reactions': True, 'offering': True, 'chemists': True, 'tailor': True, 'conditions': True, 'tool': True, 'investigate': True, 'evacuation': True, 'scale': True, 'disasters': True, 'tested': True, 'householders': True, 'decide': True, 'evacuate': True, 'wildfires': True, 'hurricanes': True, 'pre': True, 'building': True, 'fires': True, 'transformative': True, 'deliver': True, 'expected': True, 'reasons': True, 'numerous': True, 'lack': True, 'access': True, 'badly': True, 'chosen': True, 'wrong': True, 'people': True, 'resources': True, 'black': True, 'box': True, 'poses': True, 'challenge': True, 'producing': True, 'entirely': True, 'opaque': True, 'coders': True, 'audit': True, 'extracted': True, 'house': True, 'lords': True, 'select': True, 'committee': True, 'claimed': True, 'substantial': True, 'impact': True, 'life': True, 'acceptable': True, 'full': True, 'satisfactory': True, 'explanation': True, '2018': True, 'self-driving': True, 'car': True, 'uber': True, 'failed': True, 'pedestrian': True, 'killed': True, 'collision': True, 'healthcare': True, 'watson': True, 'years': True, 'billions': True, 'dollars': True, 'invested': True, 'bing': True, 'chat': True, 'chatbot': True, 'hostile': True, 'offensive': True, 'strategy': True, 'systematic': True, 'review': True, 'reviewer': True, 'burden': True, 'growth': True, 'biomedical': True, 'literature': True, 'improved': True, 'workload': True, 'limiting': True, 'necessary': True, 'sensitivity': True, 'findings': True, 'themselves': True, 'explainability': True, 'explainable': True, 'xai': True, 'interpretable': True, 'xml': True, 'humans': True, 'understand': True, 'contrasts': True, 'designers': True, 'why': True, 'arrived': True, 'refining': True, 'mental': True, 'ai-powered': True, 'dismantling': True, 'misconceptions': True, 'promises': True, 'effectively': True, 'right': True, 'settling': True, 'bad': True, 'overly': True, 'gerrymandered': True, 'past': True, 'rewarding': True, 'accordance': True, 'fits': True, 'penalizing': True, 'vulnerabilities': True, 'learners': True, 'disappoint': True, 'lesson': True, 'toy': True, 'pictures': True, 'brown': True, 'horses': True, 'cats': True, 'might': True, 'conclude': True, 'patches': True, 'unlike': True, 'classifiers': True, 'primarily': True, 'judgments': True, 'spatial': True, 'components': True, 'picture': True, 'pixels': True, 'oblivious': True, 'still': True, 'correlate': True, 'modifying': True, 'legitimate': True, 'adversarial': True, 'misclassifies': True, 'nonlinear': True, 'non-pattern': True, 'perturbations': True, 'possible': True, 'change': True, 'adversarially': True, 'pixel': True, 'vulnerable': True, 'manipulation': True, 'evasion': True, 'demonstrated': True, 'backdoors': True, 'placed': True, 'undetectably': True, 'spam': True, 'well-visible': True, 'posts': True, 'third': True, 'parties': True, 'data/software': True, 'transparency': True, 'white-box': True, 'assessments': True, 'validated': True, 'holdout': True, 'splits': True, 'conventionally': True, '2/3': True, '1/3': True, 'designation': True, 'evaluates': True, 'comparison': True, 'k-fold-cross-validation': True, 'randomly': True, 'partitions': True, 'k': True, 'experiments': True, 'performed': True, 'respectively': True, 'subset': True, 'remaining': True, 'k-1': True, 'cross-validation': True, 'bootstrap': True, 'replacement': True, 'assess': True, 'investigators': True, 'frequently': True, 'true': True, 'rate': True, 'tpr': True, 'tnr': True, 'similarly': True, 'false': True, 'fpr': True, 'fnr': True, 'rates': True, 'ratios': True, 'reveal': True, 'numerators': True, 'denominators': True, 'receiver': True, 'operating': True, 'roc': True, 'accompanying': True, 'curve': True, 'auc': True, 'offer': True, 'assessment': True, 'suffer': True, 'biases': True, 'specifically': True, 'customers': True, 'needs': True, 'groups': True, 'human-made': True, 'pick': True, 'constitutional': True, 'unconscious': True, 'present': True, 'datasets': True, 'exhibit': True, 'upon': True, 'digitizing': True, 'cultural': True, 'prejudices': True, '1988': True, 'uk': True, 'commission': True, 'racial': True, 'equality': True, 'st.': True, 'george': True, 'school': True, 'admissions': True, 'staff': True, 'denied': True, 'nearly': True, '60': True, 'candidates': True, 'women': True, 'non-european': True, 'sounding': True, 'names': True, 'job': True, 'hiring': True, 'racist': True, 'policies': True, 'duplicating': True, 'scoring': True, 'applicants': True, 'includes': True, 'policing': True, 'geolitica': True, 'resulted': True, 'disproportionately': True, 'over-policing': True, 'low-income': True, 'minority': True, 'historical': True, 'crime': True, 'responsible': True, 'documentation': True, 'critical': True, 'blame': True, 'participation': True, 'vulnerability': True, 'carried': True, 'cra': True, '2021': True, 'female': True, 'faculty': True, 'merely': True, '16.1': True, 'universities': True, 'world': True, 'furthermore': True, 'group': True, 'u.s.': True, 'resident': True, 'phd': True, 'graduates': True, '45': True, 'identified': True, 'white': True, '22.4': True, 'asian': True, '3.2': True, 'hispanic': True, '2.4': True, 'african': True, 'american': True, 'further': True, 'demonstrates': True, 'diversity': True, 'shown': True, 'contain': True, 'human-like': True, 'languages': True, 'corpora': True, '2016': True, 'tay': True, 'twitter': True, 'quickly': True, 'picked': True, 'sexist': True, 'experiment': True, 'propublica': True, 'investigative': True, 'journalism': True, 'insight': True, 'recidivism': True, 'prisoners': True, 'falsely': True, 'flagged': True, 'defendants': True, 'risk': True, 'twice': True, '2015': True, 'photos': True, 'tagged': True, 'couple': True, 'gorillas': True, 'controversy': True, 'gorilla': True, 'subsequently': True, 'removed': True, '2023': True, 'recognizing': True, 'non-white': True, 'challenges': True, 'longer': True, 'domains': True, 'concern': True, 'fairness': True, 'propelling': True, 'increasingly': True, 'expressed': True, 'scientists': True, 'fei-fei': True, 'li': True, '[': True, ']': True, 'nothing': True, 'and—most': True, 'importantly—it': True, 'powerful': True, 'beginning': True, 'profound': True, 'responsibility': True, 'incentives': True, 'concerns': True, 'health': True, 'care': True, 'professionals': True, 'designed': True, 'public': True, 'income-generating': True, 'united': True, 'states': True, 'long-standing': True, 'ethical': True, 'dilemma': True, 'improving': True, 'profits': True, 'provide': True, 'patients': True, 'unnecessary': True, 'tests': True, 'medication': True, 'proprietary': True, 'owners': True, 'hold': True, 'stakes': True, 'diagnose': True, 'medicate': True, 'plan': True, 'recovery': True, 'paths': True, 'requires': True, 'mitigated': True, 'hardware': True, 'since': True, '2010s': True, 'led': True, 'narrow': True, 'subdomain': True, 'graphics': True, 'gpus': True, 'ai-specific': True, 'enhancements': True, 'displaced': True, 'cpus': True, 'dominant': True, 'commercial': True, 'cloud': True, 'openai': True, 'largest': True, 'projects': True, 'alexnet': True, 'alphazero': True, '2017': True, '300,000-fold': True, 'increase': True, 'required': True, 'doubling-time': True, '3.4': True, 'months': True, 'neuromorphic': True, 'emulate': True, 'functionality': True, 'software-based': True, 'simulations': True, 'specialized': True, 'architectures': True, 'physical': True, 'electrically': True, 'adjustable': True, 'materials': True, 'memristors': True, 'highlights': True, 'opposed': True, 'broadly': True, 'resistance': True, 'replicate': True, 'embedded': True, 'sub-field': True, 'deployed': True, 'wearable': True, 'edge': True, 'microcontrollers': True, 'running': True, 'eliminates': True, 'transfer': True, 'servers': True, 'breaches': True, 'leaks': True, 'theft': True, 'intellectual': True, 'personal': True, 'secrets': True, 'achieved': True, 'acceleration': True, 'approximate': True, 'pruning': True, 'quantization': True, 'distillation': True, 'low-rank': True, 'architecture': True, 'parameter': True, 'sharing': True, 'suites': True, 'containing': True, 'free': True, 'open-source': True, 'editions': True, 'knime': True, 'rapidminer': True, 'ieee': True, 'aaai': True, 'conference': True, 'linguistics': True, 'acl': True, 'european': True, 'practice': True, 'international': True, 'biostatistics': True, 'cibb': True, 'icml': True, 'iclr': True, 'robots': True, 'iros': True, 'neurips': True, 'see': True, '–': True, 'automating': True, 'extremely': True, '—': True, 'differentiable': True, 'list': True, 'm-theory': True, 'unlearning': True, 'references': True, 'sources': True, 'domingos': True, 'pedro': True, 'september': True, '22': True, 'master': True, 'remake': True, 'our': True, 'books': True, 'isbn': True, '978-0465065707.': True, 'nils': True, '1998': True, 'synthesis': True, 'morgan': True, 'kaufmann': True, '978-1-55860-467-4.': True, 'archived': True, 'july': True, '2020.': True, 'retrieved': True, '18': True, 'november': True, '2019.': True, 'poole': True, 'mackworth': True, 'goebel': True, 'randy': True, 'york': True, 'oxford': True, 'university': True, 'press': True, '978-0-19-510270-3.': True, 'august': True, 'russell': True, 'stuart': True, 'j.': True, 'norvig': True, 'peter': True, '2003': True, '2nd': True, 'ed': True, 'upper': True, 'saddle': True, 'river': True, 'jersey': True, 'prentice': True, 'hall': True, '0-13-790395-2.': True, 'reading': True, 'links': True, 'mloss': True}\n",
            "\n",
            "Processed Text with Snowball stopwords and stemmer:\n",
            "machin learn field studi artifici intellig concern develop studi statist algorithm learn data general unseen data thus perform task without explicit instruct within subdisciplin machin learn advanc field deep learn allow neural network class statist algorithm surpass mani previous machin learn approach perform find applic mani field includ natur languag process comput vision speech recognit email filter agricultur medicin applic busi problem known predict analyt statist mathemat optim mathemat p\n",
            "\n",
            "Processed Text with WordNet Lemmatizer:\n",
            "machin learn field studi artifici intellig concern develop studi statist algorithm learn data gener unseen data thu perform task without explicit instruct within subdisciplin machin learn advanc field deep learn allow neural network class statist algorithm surpass mani previou machin learn approach perform find applic mani field includ natur languag process comput vision speech recognit email filter agricultur medicin applic busi problem known predict analyt statist mathemat optim mathemat progr\n"
          ]
        }
      ],
      "source": [
        "# Use Bag of Words without preprocessing\n",
        "bow_text = content.lower()\n",
        "bow_features = {word: True for word in word_tokenize(bow_text)}\n",
        "\n",
        "# Use Snowball stemmer and custom stopwords\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "processed_text_with_snowball = preprocess_text(content, found_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer)\n",
        "\n",
        "# Use WordNet lemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "processed_text_with_lemmatizer = preprocess_text(content, found_terms, stopwords_set=set(stopwords.words('english')), lemmatizer=wordnet_lemmatizer)\n",
        "\n",
        "\n",
        "print(\"\\nBag of Words without preprocessing:\")\n",
        "print(bow_features)\n",
        "\n",
        "print(\"\\nProcessed Text with Snowball stopwords and stemmer:\")\n",
        "print(processed_text_with_snowball[:500])\n",
        "\n",
        "print(\"\\nProcessed Text with WordNet Lemmatizer:\")\n",
        "print(processed_text_with_lemmatizer[:500])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYPgDOM6eiAv",
        "outputId": "a6aaa06e-4126-490b-9c76-82c69b13ff48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted class for the test text without pre-processing for Bag of Words: location\n",
            "Predicted class for the test text without pre-processing for Bag of Words: non-location\n",
            "\n",
            "Predicted class for the preprocessed test text with Snowball stop words and Snowball Stemmer for Bag of Words: location\n",
            "Predicted class for the preprocessed test text with Snowball stop words and Snowball Stemmer for Bag of Words: non-location\n"
          ]
        }
      ],
      "source": [
        "\"\"\"## Naive Bayes without Pre-processing:\"\"\"\n",
        "\n",
        "# 'geographic' and 'non-geographic' \n",
        "geographic_class = \"location\"\n",
        "non_geographic_class = \"non-location\"\n",
        "\n",
        "# Training data for Naive Bayes on Bag of Words without pre-processing\n",
        "training_data_bow_raw = [\n",
        "    (fetch_wikipedia_content(\"Florence\", location_terms)[0].lower(), geographic_class),\n",
        "    (fetch_wikipedia_content(\"Machine learning\", non_location_terms)[0].lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for raw text\n",
        "def tokenize_raw_text_bow(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for raw text\n",
        "def extract_features_raw_bow(text):\n",
        "    return {word: True for word in tokenize_raw_text_bow(text)}\n",
        "\n",
        "# Prepare the training set without pre-processing for Bag of Words\n",
        "training_set_bow_raw = [(extract_features_raw_bow(text), label) for (text, label) in training_data_bow_raw]\n",
        "\n",
        "# Train the Naive Bayes classifier without pre-processing for Bag of Words\n",
        "nb_classifier_bow_raw = NaiveBayesClassifier.train(training_set_bow_raw)\n",
        "\n",
        "# Usage without pre-processing for Bag of Words\n",
        "test_text_bow_raw = fetch_wikipedia_content(\"Florence\", location_terms)[0].lower()\n",
        "test_features_bow_raw = extract_features_raw_bow(test_text_bow_raw)\n",
        "classification_bow_raw = nb_classifier_bow_raw.classify(test_features_bow_raw)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text without pre-processing for Bag of Words: {classification_bow_raw}\")\n",
        "\n",
        "test_text_bow_raw = fetch_wikipedia_content(\"Data Science\", non_location_terms)[0].lower()\n",
        "test_features_bow_raw = extract_features_raw_bow(test_text_bow_raw)\n",
        "classification_bow_raw = nb_classifier_bow_raw.classify(test_features_bow_raw)\n",
        "\n",
        "print(f\"Predicted class for the test text without pre-processing for Bag of Words: {classification_bow_raw}\")\n",
        "\n",
        "\"\"\"## Naive Bayes with Pre-processing:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Training data for Naive Bayes with Snowball stop words and Snowball Stemmer\n",
        "training_data_bow_snowball = [\n",
        "    (preprocess_text(fetch_wikipedia_content(\"Florence\", location_terms)[0], location_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(), geographic_class),\n",
        "    (preprocess_text(fetch_wikipedia_content(\"Machine learning\", non_location_terms)[0], non_location_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(),\n",
        "                                non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for preprocessed text\n",
        "def tokenize_preprocessed_text_bow(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for preprocessed text\n",
        "def extract_features_preprocessed_bow(text):\n",
        "    return {word: True for word in tokenize_preprocessed_text_bow(text)}\n",
        "\n",
        "# Prepare the training set with Snowball stop words and Snowball Stemmer for Bag of Words\n",
        "training_set_bow_snowball = [(extract_features_preprocessed_bow(text), label) for (text, label) in training_data_bow_snowball]\n",
        "\n",
        "# Train the Naive Bayes classifier with Snowball stop words and Snowball Stemmer for Bag of Words\n",
        "nb_classifier_bow_snowball = NaiveBayesClassifier.train(training_set_bow_snowball)\n",
        "\n",
        "# Usage with Snowball stop words and Snowball Stemmer for Bag of Words\n",
        "test_text_bow_snowball = preprocess_text(fetch_wikipedia_content(\"Florence\", location_terms)[0], location_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer).lower()\n",
        "test_features_bow_snowball = extract_features_preprocessed_bow(test_text_bow_snowball)\n",
        "classification_bow_snowball = nb_classifier_bow_snowball.classify(test_features_bow_snowball)\n",
        "\n",
        "print(f\"\\nPredicted class for the preprocessed test text with Snowball stop words and Snowball Stemmer for Bag of Words: {classification_bow_snowball}\")\n",
        "\n",
        "test_text_bow_snowball = preprocess_text(fetch_wikipedia_content(\"Data Science\", non_location_terms)[0], non_location_terms, stopwords_set=set(stopwords.words('english')),\n",
        "                                                 stemmer=snowball_stemmer).lower()\n",
        "test_features_bow_snowball = extract_features_preprocessed_bow(test_text_bow_snowball)\n",
        "classification_bow_snowball = nb_classifier_bow_snowball.classify(test_features_bow_snowball)\n",
        "\n",
        "print(f\"Predicted class for the preprocessed test text with Snowball stop words and Snowball Stemmer for Bag of Words: {classification_bow_snowball}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX0lhK4luNCQ",
        "outputId": "b45d8638-a6f1-4360-a62d-c924bf968c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicted class for the test text using Logistic Regression with pre-processing: location\n",
            "Predicted class for the test text using Logistic Regression with pre-processing: non-location\n",
            "\n",
            "Predicted class for the test text using Logistic Regression without pre-processing: location\n",
            "Predicted class for the test text using Logistic Regression without pre-processing: non-location\n"
          ]
        }
      ],
      "source": [
        "\"\"\"## Logistic Regression\n",
        "\n",
        "### Training data for Logistic Regression with pre-processing from Naive Bayes\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "logistic_train_data_preprocessed = [\n",
        "    (preprocess_text(fetch_wikipedia_content(\"Florence\", location_terms)[0], location_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(),\n",
        "                            geographic_class),\n",
        "    (preprocess_text(fetch_wikipedia_content(\"Machine learning\", non_location_terms)[0], non_location_terms, stopwords_set=set(stopwords.words('english')), stemmer=snowball_stemmer).lower(),\n",
        "                            non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for preprocessed text \n",
        "def tokenize_preprocessed_logistic_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for preprocessed text \n",
        "def extract_preprocessed_logistic_features(text):\n",
        "    return ' '.join(tokenize_preprocessed_logistic_text(text))\n",
        "\n",
        "# Prepare the training set for Logistic Regression with pre-processing\n",
        "logistic_train_set_preprocessed = [(extract_preprocessed_logistic_features(text), label) for (text, label) in logistic_train_data_preprocessed]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression with pre-processing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Separate features (X) and labels (y) for Logistic Regression with pre-processing\n",
        "X_train_logistic_preprocessed = [text for (text, _) in logistic_train_set_preprocessed]\n",
        "y_train_logistic_preprocessed = [label for (_, label) in logistic_train_set_preprocessed]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression with pre-processing\n",
        "tfidf_vectorizer_logistic_preprocessed = TfidfVectorizer()\n",
        "X_train_tfidf_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.fit_transform(X_train_logistic_preprocessed)\n",
        "\n",
        "# Train the Logistic Regression classifier with pre-processing\n",
        "logistic_regressor_preprocessed = LogisticRegression()\n",
        "logistic_regressor_preprocessed.fit(X_train_tfidf_logistic_preprocessed, y_train_logistic_preprocessed)\n",
        "\n",
        "# Usage for Logistic Regression with pre-processing\n",
        "test_text_logistic_preprocessed = preprocess_text(fetch_wikipedia_content(\"Florence\", location_terms)[0], location_terms, stopwords_set=set(stopwords.words('english')),\n",
        "                                                          stemmer=snowball_stemmer).lower()\n",
        "test_features_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.transform([extract_preprocessed_logistic_features(test_text_logistic_preprocessed)])\n",
        "predicted_class_logistic_preprocessed = logistic_regressor_preprocessed.predict(test_features_logistic_preprocessed)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text using Logistic Regression with pre-processing: {predicted_class_logistic_preprocessed[0]}\")\n",
        "\n",
        "test_text_logistic_preprocessed = preprocess_text(fetch_wikipedia_content(\"Data Science\", non_location_terms)[0], non_location_terms, stopwords_set=set(stopwords.words('english')),\n",
        "                                                          stemmer=snowball_stemmer).lower()\n",
        "test_features_logistic_preprocessed = tfidf_vectorizer_logistic_preprocessed.transform([extract_preprocessed_logistic_features(test_text_logistic_preprocessed)])\n",
        "predicted_class_logistic_preprocessed = logistic_regressor_preprocessed.predict(test_features_logistic_preprocessed)\n",
        "\n",
        "print(f\"Predicted class for the test text using Logistic Regression with pre-processing: {predicted_class_logistic_preprocessed[0]}\")\n",
        "\n",
        "# Training data for Logistic Regression without pre-processing\n",
        "logistic_train_data_raw = [\n",
        "    (fetch_wikipedia_content(\"Florence\", location_terms)[0].lower(), geographic_class),\n",
        "    (fetch_wikipedia_content(\"Machine learning\", non_location_terms)[0].lower(), non_geographic_class),\n",
        "]\n",
        "\n",
        "# Tokenizer function for raw text\n",
        "def tokenize_raw_logistic_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Feature extraction function for raw text\n",
        "def extract_raw_logistic_features(text):\n",
        "    return ' '.join(tokenize_raw_logistic_text(text))\n",
        "\n",
        "# Prepare the training set for Logistic Regression without pre-processing\n",
        "logistic_train_set_raw = [(extract_raw_logistic_features(text), label) for (text, label) in logistic_train_data_raw]\n",
        "\n",
        "# Create TF-IDF vectors from the training set for Logistic Regression without pre-processing\n",
        "X_train_logistic_raw = [text for (text, _) in logistic_train_set_raw]\n",
        "y_train_logistic_raw = [label for (_, label) in logistic_train_set_raw]\n",
        "\n",
        "tfidf_vectorizer_logistic_raw = TfidfVectorizer()\n",
        "X_train_tfidf_logistic_raw = tfidf_vectorizer_logistic_raw.fit_transform(X_train_logistic_raw)\n",
        "\n",
        "# Train the Logistic Regression classifier without pre-processing\n",
        "logistic_regressor_raw = LogisticRegression()\n",
        "logistic_regressor_raw.fit(X_train_tfidf_logistic_raw, y_train_logistic_raw)\n",
        "\n",
        "\"\"\"### Usage for Logistic Regression without pre-processing\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "test_text_logistic_raw = fetch_wikipedia_content(\"Florence\", location_terms)[0].lower()\n",
        "test_features_logistic_raw = tfidf_vectorizer_logistic_raw.transform([extract_raw_logistic_features(test_text_logistic_raw)])\n",
        "predicted_class_logistic_raw = logistic_regressor_raw.predict(test_features_logistic_raw)\n",
        "\n",
        "print(f\"\\nPredicted class for the test text using Logistic Regression without pre-processing: {predicted_class_logistic_raw[0]}\")\n",
        "\n",
        "test_text_logistic_raw = fetch_wikipedia_content(\"Data Science\", non_location_terms)[0].lower()\n",
        "test_features_logistic_raw = tfidf_vectorizer_logistic_raw.transform([extract_raw_logistic_features(test_text_logistic_raw)])\n",
        "predicted_class_logistic_raw = logistic_regressor_raw.predict(test_features_logistic_raw)\n",
        "\n",
        "print(f\"Predicted class for the test text using Logistic Regression without pre-processing: {predicted_class_logistic_raw[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cFV-jsOuQ-Q",
        "outputId": "0b5b9026-f7d2-4d40-d619-043ed7eacb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing Naive Bayes Classifier ===\n",
            "Rome: location\n",
            "Tokyo: location\n",
            "Berlin: location\n",
            "Computer Vision: non-location\n",
            "Natural Language Processing: non-location\n",
            "Deep Learning: non-location\n",
            "\n",
            "=== Testing Logistic Regression Classifier ===\n",
            "Rome: location\n",
            "Tokyo: location\n",
            "Berlin: location\n",
            "Computer Vision: non-location\n",
            "Natural Language Processing: non-location\n",
            "Deep Learning: non-location\n",
            "\n",
            "Classifier Performance:\n",
            "Naive Bayes accuracy on test cases: 1.00\n",
            "Logistic Regression accuracy score: 1.00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class TextClassifier:\n",
        "    \"\"\"\n",
        "    A class to handle text classification with different models and preprocessing\n",
        "    \"\"\"\n",
        "    def __init__(self, location_terms, non_location_terms):\n",
        "        self.location_terms = location_terms\n",
        "        self.non_location_terms = non_location_terms\n",
        "        self.geographic_class = \"location\"\n",
        "        self.non_geographic_class = \"non-location\"\n",
        "\n",
        "    def prepare_training_data(self, use_preprocessing=True):\n",
        "        \"\"\"Prepare training data with or without preprocessing\"\"\"\n",
        "        training_examples = [\n",
        "            (\"Florence\", self.location_terms, self.geographic_class),\n",
        "            (\"Paris\", self.location_terms, self.geographic_class),\n",
        "            (\"London\", self.location_terms, self.geographic_class),\n",
        "            (\"Machine Learning\", self.non_location_terms, self.non_geographic_class),\n",
        "            (\"Data Science\", self.non_location_terms, self.non_geographic_class),\n",
        "            (\"Artificial Intelligence\", self.non_location_terms, self.non_geographic_class)\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "        for topic, terms, label in training_examples:\n",
        "            content = fetch_wikipedia_content(topic, terms)[0]\n",
        "            if content:\n",
        "                if use_preprocessing:\n",
        "                    processed_text = preprocess_text(\n",
        "                        content,\n",
        "                        terms,\n",
        "                        stemmer=SnowballStemmer('english')\n",
        "                    ).lower()\n",
        "                    results.append((processed_text, label))\n",
        "                else:\n",
        "                    results.append((content.lower(), label))\n",
        "        return results\n",
        "\n",
        "    def extract_features(self, text):\n",
        "        \"\"\"Extract features for Naive Bayes\"\"\"\n",
        "        # Tokenize and create word frequency dictionary instead of binary features\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        word_freq = {}\n",
        "        for token in tokens:\n",
        "            if token.isalpha() and len(token) > 2:  # Only consider alphabetic tokens longer than 2 chars\n",
        "                word_freq[token] = word_freq.get(token, 0) + 1\n",
        "        return word_freq\n",
        "\n",
        "    def train_naive_bayes(self, use_preprocessing=True):\n",
        "        \"\"\"Train Naive Bayes classifier\"\"\"\n",
        "        training_data = self.prepare_training_data(use_preprocessing)\n",
        "        training_set = [(self.extract_features(text), label)\n",
        "                       for (text, label) in training_data]\n",
        "        return NaiveBayesClassifier.train(training_set)\n",
        "\n",
        "    def train_logistic_regression(self, use_preprocessing=True):\n",
        "        \"\"\"Train Logistic Regression classifier with improved vectorization\"\"\"\n",
        "        training_data = self.prepare_training_data(use_preprocessing)\n",
        "\n",
        "        X_train = [text for (text, _) in training_data]\n",
        "        y_train = [label for (_, label) in training_data]\n",
        "\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=1000,  # Limit features to avoid overfitting\n",
        "            min_df=2,          # Ignore terms that appear in less than 2 documents\n",
        "            max_df=0.95,       # Ignore terms that appear in more than 95% of documents\n",
        "            ngram_range=(1, 2) # Use both unigrams and bigrams\n",
        "        )\n",
        "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "        \n",
        "        classifier = LogisticRegression(\n",
        "            C=1.0,            # Regularization strength\n",
        "            class_weight='balanced', # Handle class imbalance\n",
        "            random_state=42   # For reproducibility\n",
        "        )\n",
        "        classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        return classifier, vectorizer\n",
        "\n",
        "    def test_classifiers(self):\n",
        "        \"\"\"Test both classifiers on multiple examples\"\"\"\n",
        "        test_cases = [\n",
        "            (\"Rome\", self.location_terms, self.geographic_class),\n",
        "            (\"Tokyo\", self.location_terms, self.geographic_class),\n",
        "            (\"Berlin\", self.location_terms, self.geographic_class),\n",
        "            (\"Computer Vision\", self.non_location_terms, self.non_geographic_class),\n",
        "            (\"Natural Language Processing\", self.non_location_terms, self.non_geographic_class),\n",
        "            (\"Deep Learning\", self.non_location_terms, self.non_geographic_class)\n",
        "        ]\n",
        "\n",
        "        print(\"\\n=== Testing Naive Bayes Classifier ===\")\n",
        "        nb_classifier = self.train_naive_bayes(use_preprocessing=True)\n",
        "\n",
        "        nb_correct = 0\n",
        "        nb_total = 0\n",
        "\n",
        "        for topic, terms, expected in test_cases:\n",
        "            content = fetch_wikipedia_content(topic, terms)[0]\n",
        "            if content:\n",
        "                # Test with preprocessing\n",
        "                processed_text = preprocess_text(\n",
        "                    content,\n",
        "                    terms,\n",
        "                    stemmer=SnowballStemmer('english')\n",
        "                ).lower()\n",
        "                features = self.extract_features(processed_text)\n",
        "                prediction = nb_classifier.classify(features)\n",
        "                print(f\"{topic}: {prediction}\")\n",
        "\n",
        "                # Update accuracy counters\n",
        "                if prediction == expected:\n",
        "                    nb_correct += 1\n",
        "                nb_total += 1\n",
        "\n",
        "        print(\"\\n=== Testing Logistic Regression Classifier ===\")\n",
        "        logistic_classifier, vectorizer = self.train_logistic_regression(use_preprocessing=True)\n",
        "\n",
        "        # Keep track of correct predictions for accuracy calculation\n",
        "        lr_correct = 0\n",
        "        lr_total = 0\n",
        "\n",
        "        for topic, terms, expected in test_cases:\n",
        "            # Get content and preprocess\n",
        "            content = fetch_wikipedia_content(topic, terms)[0]\n",
        "            if content:\n",
        "                # Test with preprocessing\n",
        "                processed_text = preprocess_text(\n",
        "                    content,\n",
        "                    terms,\n",
        "                    stemmer=SnowballStemmer('english')\n",
        "                ).lower()\n",
        "                features = vectorizer.transform([processed_text])\n",
        "                prediction = logistic_classifier.predict(features)[0]\n",
        "                print(f\"{topic}: {prediction}\")\n",
        "\n",
        "                # Update accuracy counters\n",
        "                if prediction == expected:\n",
        "                    lr_correct += 1\n",
        "                lr_total += 1\n",
        "\n",
        "        # Print classifier accuracy\n",
        "        print(\"\\nClassifier Performance:\")\n",
        "        nb_accuracy = nb_correct / nb_total if nb_total > 0 else 0\n",
        "        lr_accuracy = lr_correct / lr_total if lr_total > 0 else 0\n",
        "        print(f\"Naive Bayes accuracy on test cases: {nb_accuracy:.2f}\")\n",
        "        print(f\"Logistic Regression accuracy score: {lr_accuracy:.2f}\")\n",
        "\n",
        "\n",
        "classifier = TextClassifier(location_terms, non_location_terms)\n",
        "\n",
        "# Train and test models\n",
        "classifier.test_classifiers()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
